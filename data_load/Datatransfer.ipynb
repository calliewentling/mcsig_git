{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ccd6d2b",
   "metadata": {},
   "source": [
    "# POSTGRES VIA Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9904e6c8",
   "metadata": {},
   "source": [
    "https://www.dataquest.io/blog/loading-data-into-postgres/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a43e83",
   "metadata": {},
   "source": [
    "### Initialize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb7bdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\mcsig_thesis\\datatransfer\\lib\\site-packages (2.8.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\mcsig_thesis\\datatransfer\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f7a315",
   "metadata": {},
   "source": [
    "### Connect to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f750337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection open\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "#Connect to postgres\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "print(\"Connection open\")\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25680fa",
   "metadata": {},
   "source": [
    "### Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0250da47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mensagem_stories dropped\n",
      "mensagem_stories committed\n",
      "connection closed\n"
     ]
    }
   ],
   "source": [
    "#Connect to postgres\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE mensagem_stories\")\n",
    "print (\"mensagem_stories dropped\")\n",
    "\n",
    "#Create table mensagem_stories\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE mensagem_stories(\n",
    "    title text,\n",
    "    summary text,\n",
    "    contents text,\n",
    "    pub_date date,\n",
    "    spatial text,\n",
    "    t_begin date,\n",
    "    t_end date,\n",
    "    t_type text,\n",
    "    temporal text,\n",
    "    link text,\n",
    "    section text,\n",
    "    tags text,\n",
    "    author text,\n",
    "    publication text\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"mensagem_stories committed\")\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "print(\"connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923212a",
   "metadata": {},
   "source": [
    "## Load data from CSV\n",
    "Currently setting null date values to 01/01/1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c36e8776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection open\n",
      "current working directory is  C:\\\n",
      "current working directory is  C:\\\n",
      "Path changed\n",
      "data loaded\n",
      "load id assigned\n",
      "[('Esta cidade ja é para animais vadios: gatos de rua têm abrigos para dormir', 'Maria João Martins', 'A1', 1), ('A avó da Uber Eats em Alfama é a salvaçao dos mais velhos', 'Álvaro Filho', 'A2', 2), ('Alvalade: o bairro que não é para turistas tem resistido melhor à crise da pendemia', 'Frederico Raposo ', 'A3', 3), ('\"As \"\"Gaulesas\"\" que defendem a Mouraria da especulação imobiliária\"', 'Catarina Reis', 'A4', 4), ('Mais floreiras e menos carros. Estes lisboetas mudaram uma rua com um canteiro.', 'Frederico Raposo ', 'A5', 5), ('Nos Anjos, o ativismo passou a fazer-se ao microfone da rádio Gabriela', 'Álvaro Filho', 'A6', 6), ('Quem é Alexis Lapas, o peixeiro de Benfica que dá polémica no Twitter', 'Álvaro Filho', 'A7', 7), ('A guerra das bicicletas passou para a Avenida de Berna e está a politizar-se', 'Frederico Raposo ', 'A8', 8)]\n",
      "connection closed\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "print(\"Connection open\")\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(\"current working directory is \", cwd)\n",
    "\n",
    "os.chdir(\"C:\\\\\")\n",
    "cwd = os.getcwd()\n",
    "print(\"current working directory is \", cwd)\n",
    "\n",
    "path = os.path.join('mcsig_git', 'data_load')\n",
    "os.chdir(path)\n",
    "print(\"Path changed\")\n",
    "\n",
    "\n",
    "#Load table\n",
    "with open('story2.csv', 'r', encoding='utf-8') as f:\n",
    "    next(f) #skip header row\n",
    "    cur.copy_from(f, 'mensagem_stories', sep='|')\n",
    "conn.commit()\n",
    "print(\"data loaded\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    ALTER TABLE mensagem_stories ADD id serial PRIMARY KEY, ADD load_id text DEFAULT 'A'\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    UPDATE mensagem_stories\n",
    "    set load_id = CONCAT('A',id)\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"load id assigned\")\n",
    "\n",
    "cur.execute('SELECT title,author,load_id,id FROM mensagem_stories')\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "conn.close()\n",
    "print(\"connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa63d6a0",
   "metadata": {},
   "source": [
    "## Create Relational Database model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af72154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story dropped\n",
      "story created\n",
      "author dropped\n",
      "author created\n",
      "authorship dropped\n",
      "authorship created\n",
      "connection closed\n"
     ]
    }
   ],
   "source": [
    "#Connect to postgres\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS story CASCADE\")\n",
    "print (\"story dropped\")\n",
    "\n",
    "#Create table story\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE story(\n",
    "    title text NOT NULL,\n",
    "    summary text,\n",
    "    contents text,\n",
    "    web_link text,\n",
    "    publish_date date,\n",
    "    load_id text,\n",
    "    story_id serial PRIMARY KEY\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"story created\")\n",
    "\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS author CASCADE\")\n",
    "print (\"author dropped\")\n",
    "\n",
    "#Create table author\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE author(\n",
    "    author_name text NOT NULL,\n",
    "    author_id serial PRIMARY KEY\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"author created\")\n",
    "\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS authorship\")\n",
    "print (\"authorship dropped\")\n",
    "\n",
    "#Create table mensagem_stories\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE authorship(\n",
    "    story_id INT NOT NULL,\n",
    "    author_id INT NOT NULL,\n",
    "    PRIMARY KEY (story_id, author_id),\n",
    "    FOREIGN KEY (story_id) REFERENCES story(story_id) ON UPDATE CASCADE,\n",
    "    FOREIGN KEY (author_id) REFERENCES author(author_id) ON UPDATE CASCADE\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"authorship created\")\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "print(\"connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288563f0",
   "metadata": {},
   "source": [
    "## Distribute into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9386bbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stories loaded\n",
      "[('Esta cidade ja é para animais vadios: gatos de rua têm abrigos para dormir', 'A1', 1), ('A avó da Uber Eats em Alfama é a salvaçao dos mais velhos', 'A2', 2), ('Alvalade: o bairro que não é para turistas tem resistido melhor à crise da pendemia', 'A3', 3), ('\"As \"\"Gaulesas\"\" que defendem a Mouraria da especulação imobiliária\"', 'A4', 4), ('Mais floreiras e menos carros. Estes lisboetas mudaram uma rua com um canteiro.', 'A5', 5), ('Nos Anjos, o ativismo passou a fazer-se ao microfone da rádio Gabriela', 'A6', 6), ('Quem é Alexis Lapas, o peixeiro de Benfica que dá polémica no Twitter', 'A7', 7), ('A guerra das bicicletas passou para a Avenida de Berna e está a politizar-se', 'A8', 8)]\n",
      "authors loaded\n",
      "[('Álvaro Filho', 1), ('Frederico Raposo ', 2), ('Catarina Reis', 3), ('Maria João Martins', 4)]\n",
      "connection closed\n"
     ]
    }
   ],
   "source": [
    "#Connect to postgres\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#Distribute mensagem stories into stories\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO story(title, summary, contents, web_link, publish_date, load_id)\n",
    "    SELECT title, summary, contents, link, pub_date, load_id\n",
    "    FROM mensagem_stories\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"stories loaded\")\n",
    "\n",
    "cur.execute('SELECT title,load_id,story_id FROM story')\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "#Distribute mensagem authors into authors\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO author(author_name)\n",
    "    SELECT DISTINCT author\n",
    "    FROM mensagem_stories\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"authors loaded\")\n",
    "\n",
    "cur.execute('SELECT * FROM author')\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "print(\"connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ce99d",
   "metadata": {},
   "source": [
    "## Populate authorship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de339ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection open\n",
      "[(1, 4), (2, 1), (3, 2), (4, 3), (5, 2), (6, 1), (7, 1), (8, 2)]\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "#Connect to postgres\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "print(\"Connection open\")\n",
    "\n",
    "#Relate stories and authors\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO authorship(story_id,author_id)\n",
    "    SELECT mensagem_stories.id, author.author_id\n",
    "    FROM mensagem_stories\n",
    "    LEFT JOIN author ON mensagem_stories.author = author.author_name\n",
    "    LEFT JOIN story ON mensagem_stories.load_id = story.load_id\n",
    "    ORDER BY mensagem_stories.id\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "cur.execute('SELECT * FROM authorship')\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117ccb97",
   "metadata": {},
   "source": [
    "## See all articles by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d92dcf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection open\n",
      "[('Álvaro Filho', 'A avó da Uber Eats em Alfama é a salvaçao dos mais velhos'), ('Álvaro Filho', 'Nos Anjos, o ativismo passou a fazer-se ao microfone da rádio Gabriela'), ('Álvaro Filho', 'Quem é Alexis Lapas, o peixeiro de Benfica que dá polémica no Twitter'), ('Catarina Reis', '\"As \"\"Gaulesas\"\" que defendem a Mouraria da especulação imobiliária\"'), ('Frederico Raposo ', 'A guerra das bicicletas passou para a Avenida de Berna e está a politizar-se'), ('Frederico Raposo ', 'Alvalade: o bairro que não é para turistas tem resistido melhor à crise da pendemia'), ('Frederico Raposo ', 'Mais floreiras e menos carros. Estes lisboetas mudaram uma rua com um canteiro.'), ('Maria João Martins', 'Esta cidade ja é para animais vadios: gatos de rua têm abrigos para dormir')]\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "#Connect to postgres\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "print(\"Connection open\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT author.author_name, story.title\n",
    "    FROM author\n",
    "    LEFT JOIN authorship ON author.author_id = authorship.author_id\n",
    "    INNER JOIN story ON authorship.story_id = story.story_id\n",
    "    ORDER BY author.author_name\n",
    "\"\"\")\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b02dd",
   "metadata": {},
   "source": [
    "## Add Publisher / Publishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8c67c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publisher dropped\n",
      "publisher created\n",
      "publishing dropped\n",
      "publishing created\n",
      "publishers loaded\n",
      "[('mensagem', None, None, 1)]\n",
      "[(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n",
      "[('mensagem', 'Esta cidade ja é para animais vadios: gatos de rua têm abrigos para dormir'), ('mensagem', 'A avó da Uber Eats em Alfama é a salvaçao dos mais velhos'), ('mensagem', 'Alvalade: o bairro que não é para turistas tem resistido melhor à crise da pendemia'), ('mensagem', '\"As \"\"Gaulesas\"\" que defendem a Mouraria da especulação imobiliária\"'), ('mensagem', 'Mais floreiras e menos carros. Estes lisboetas mudaram uma rua com um canteiro.'), ('mensagem', 'Nos Anjos, o ativismo passou a fazer-se ao microfone da rádio Gabriela'), ('mensagem', 'Quem é Alexis Lapas, o peixeiro de Benfica que dá polémica no Twitter'), ('mensagem', 'A guerra das bicicletas passou para a Avenida de Berna e está a politizar-se')]\n",
      "connection closed\n"
     ]
    }
   ],
   "source": [
    "#Connect to postgres\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS publisher CASCADE\")\n",
    "print (\"publisher dropped\")\n",
    "\n",
    "\n",
    "#Create table publisher\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE publisher(\n",
    "    publisher_name text NOT NULL,\n",
    "    publisher_site text,\n",
    "    publisher_description text,\n",
    "    publisher_id serial PRIMARY KEY\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"publisher created\")\n",
    "\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS publishing\")\n",
    "print (\"publishing dropped\")\n",
    "\n",
    "#Create table publishing\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE publishing(\n",
    "    story_id INT NOT NULL,\n",
    "    publisher_id INT NOT NULL,\n",
    "    PRIMARY KEY (story_id, publisher_id),\n",
    "    FOREIGN KEY (story_id) REFERENCES story(story_id) ON UPDATE CASCADE,\n",
    "    FOREIGN KEY (publisher_id) REFERENCES publisher(publisher_id) ON UPDATE CASCADE\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"publishing created\")\n",
    "\n",
    "#Distribute publishers\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO publisher(publisher_name)\n",
    "    SELECT DISTINCT publication\n",
    "    FROM mensagem_stories\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"publishers loaded\")\n",
    "\n",
    "cur.execute('SELECT * FROM publisher')\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "#Relate stories and authors\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO publishing(story_id,publisher_id)\n",
    "    SELECT mensagem_stories.id, publisher.publisher_id\n",
    "    FROM mensagem_stories\n",
    "    LEFT JOIN publisher ON mensagem_stories.publication = publisher.publisher_name\n",
    "    LEFT JOIN story ON mensagem_stories.load_id = story.load_id\n",
    "    ORDER BY mensagem_stories.id\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "cur.execute('SELECT * FROM publishing')\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT publisher.publisher_name, story.title\n",
    "    FROM publisher\n",
    "    LEFT JOIN publishing ON publisher.publisher_id = publishing.publisher_id\n",
    "    INNER JOIN story ON publishing.story_id = story.story_id\n",
    "    ORDER BY publisher.publisher_name\n",
    "\"\"\")\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "print(\"connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5207b9ce",
   "metadata": {},
   "source": [
    "## Add Section / Sectioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0749ddb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "section dropped\n",
      "section created\n",
      "sectioning dropped\n",
      "sectioning created\n",
      "sections loaded\n",
      "[('cidade', 1), ('bairros', 2)]\n",
      "[(1, 2), (2, 2), (3, 2), (4, 2), (5, 2), (6, 2), (7, 2), (8, 1)]\n",
      "[('bairros', 'Esta cidade ja é para animais vadios: gatos de rua têm abrigos para dormir'), ('bairros', 'A avó da Uber Eats em Alfama é a salvaçao dos mais velhos'), ('bairros', 'Alvalade: o bairro que não é para turistas tem resistido melhor à crise da pendemia'), ('bairros', '\"As \"\"Gaulesas\"\" que defendem a Mouraria da especulação imobiliária\"'), ('bairros', 'Mais floreiras e menos carros. Estes lisboetas mudaram uma rua com um canteiro.'), ('bairros', 'Nos Anjos, o ativismo passou a fazer-se ao microfone da rádio Gabriela'), ('bairros', 'Quem é Alexis Lapas, o peixeiro de Benfica que dá polémica no Twitter'), ('cidade', 'A guerra das bicicletas passou para a Avenida de Berna e está a politizar-se')]\n",
      "connection closed\n"
     ]
    }
   ],
   "source": [
    "#Connect to postgres\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS section CASCADE\")\n",
    "print (\"section dropped\")\n",
    "\n",
    "\n",
    "#Create table publisher\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE section(\n",
    "    section_name text NOT NULL,\n",
    "    section_id serial PRIMARY KEY\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"section created\")\n",
    "\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS sectioning\")\n",
    "print (\"sectioning dropped\")\n",
    "\n",
    "#Create table publishing\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE sectioning(\n",
    "    story_id INT NOT NULL,\n",
    "    section_id INT NOT NULL,\n",
    "    PRIMARY KEY (story_id, section_id),\n",
    "    FOREIGN KEY (story_id) REFERENCES story(story_id) ON UPDATE CASCADE,\n",
    "    FOREIGN KEY (section_id) REFERENCES section(section_id) ON UPDATE CASCADE\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"sectioning created\")\n",
    "\n",
    "#Distribute publishers\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO section(section_name)\n",
    "    SELECT DISTINCT section\n",
    "    FROM mensagem_stories\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"sections loaded\")\n",
    "\n",
    "cur.execute('SELECT * FROM section')\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "#Relate stories and sections\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO sectioning(story_id,section_id)\n",
    "    SELECT mensagem_stories.id, section.section_id\n",
    "    FROM mensagem_stories\n",
    "    LEFT JOIN section ON mensagem_stories.section = section.section_name\n",
    "    LEFT JOIN story ON mensagem_stories.load_id = story.load_id\n",
    "    ORDER BY mensagem_stories.id\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "cur.execute('SELECT * FROM sectioning')\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT section.section_name, story.title\n",
    "    FROM section\n",
    "    LEFT JOIN sectioning ON section.section_id = sectioning.section_id\n",
    "    INNER JOIN story ON sectioning.story_id = story.story_id\n",
    "    ORDER BY section.section_name\n",
    "\"\"\")\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "print(\"connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0bdffb",
   "metadata": {},
   "source": [
    "## Theme / Theming (Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9fab988e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theme dropped\n",
      "theme created\n",
      "theming dropped\n",
      "theming created\n",
      "themes loaded\n",
      "[('', 1)]\n",
      "[(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n",
      "[('', 'Esta cidade ja é para animais vadios: gatos de rua têm abrigos para dormir'), ('', 'A avó da Uber Eats em Alfama é a salvaçao dos mais velhos'), ('', 'Alvalade: o bairro que não é para turistas tem resistido melhor à crise da pendemia'), ('', '\"As \"\"Gaulesas\"\" que defendem a Mouraria da especulação imobiliária\"'), ('', 'Mais floreiras e menos carros. Estes lisboetas mudaram uma rua com um canteiro.'), ('', 'Nos Anjos, o ativismo passou a fazer-se ao microfone da rádio Gabriela'), ('', 'Quem é Alexis Lapas, o peixeiro de Benfica que dá polémica no Twitter'), ('', 'A guerra das bicicletas passou para a Avenida de Berna e está a politizar-se')]\n",
      "connection closed\n"
     ]
    }
   ],
   "source": [
    "#Connect to postgres\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS theme CASCADE\")\n",
    "print (\"theme dropped\")\n",
    "\n",
    "\n",
    "#Create table theme\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE theme(\n",
    "    theme_name text NOT NULL,\n",
    "    theme_id serial PRIMARY KEY\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"theme created\")\n",
    "\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS stheming\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS theming\")\n",
    "print (\"theming dropped\")\n",
    "\n",
    "#Create table theming\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE theming(\n",
    "    story_id INT NOT NULL,\n",
    "    theme_id INT NOT NULL,\n",
    "    PRIMARY KEY (story_id, theme_id),\n",
    "    FOREIGN KEY (story_id) REFERENCES story(story_id) ON UPDATE CASCADE,\n",
    "    FOREIGN KEY (theme_id) REFERENCES theme(theme_id) ON UPDATE CASCADE\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"theming created\")\n",
    "\n",
    "#Distribute publishers\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO theme(theme_name)\n",
    "    SELECT DISTINCT tags\n",
    "    FROM mensagem_stories\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"themes loaded\")\n",
    "\n",
    "cur.execute('SELECT * FROM theme')\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "#Relate stories and themes\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO theming(story_id,theme_id)\n",
    "    SELECT mensagem_stories.id, theme.theme_id\n",
    "    FROM mensagem_stories\n",
    "    LEFT JOIN theme ON mensagem_stories.tags = theme.theme_name\n",
    "    LEFT JOIN story ON mensagem_stories.load_id = story.load_id\n",
    "    ORDER BY mensagem_stories.id\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "cur.execute('SELECT * FROM theming')\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT theme.theme_name, story.title\n",
    "    FROM theme\n",
    "    LEFT JOIN theming ON theme.theme_id = theming.theme_id\n",
    "    INNER JOIN story ON theming.story_id = story.story_id\n",
    "    ORDER BY theme.theme_name\n",
    "\"\"\")\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "print(\"connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8e1db0",
   "metadata": {},
   "source": [
    "## Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88e6bc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employment dropped\n",
      "employment created\n",
      "[(1, 1), (1, 2), (1, 3), (1, 4)]\n",
      "[('Álvaro Filho', 'mensagem'), ('Catarina Reis', 'mensagem'), ('Frederico Raposo ', 'mensagem'), ('Maria João Martins', 'mensagem')]\n",
      "connection closed\n"
     ]
    }
   ],
   "source": [
    "#Connect to postgres\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS employment CASCADE\")\n",
    "print (\"employment dropped\")\n",
    "\n",
    "\n",
    "#Create table employment\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE employment(\n",
    "    publisher_id INT NOT NULL,\n",
    "    author_id INT NOT NULL,\n",
    "    PRIMARY KEY (publisher_id, author_id),\n",
    "    FOREIGN KEY (publisher_id) REFERENCES publisher(publisher_id) ON UPDATE CASCADE,\n",
    "    FOREIGN KEY (author_id) REFERENCES author(author_id) ON UPDATE CASCADE\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"employment created\")\n",
    "\n",
    "\n",
    "#Relate authors and publishers\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO employment(publisher_id,author_id)\n",
    "    SELECT DISTINCT publisher.publisher_id, author.author_id\n",
    "    FROM mensagem_stories\n",
    "    LEFT JOIN author ON mensagem_stories.author = author.author_name\n",
    "    LEFT JOIN publisher ON mensagem_stories.publication = publisher.publisher_name\n",
    "    ORDER BY author.author_id\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "cur.execute('SELECT * FROM employment')\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT author.author_name, publisher.publisher_name\n",
    "    FROM author\n",
    "    LEFT JOIN employment ON author.author_id = employment.author_id\n",
    "    INNER JOIN publisher ON employment.publisher_id = publisher.publisher_id\n",
    "    ORDER BY author.author_name\n",
    "\"\"\")\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "print(\"connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c4cb49",
   "metadata": {},
   "source": [
    "## Story Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ed411db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storyref dropped\n",
      "storyref created\n",
      "storyref empty\n",
      "connection closed\n"
     ]
    }
   ],
   "source": [
    "#Connect to postgres\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS storyref CASCADE\")\n",
    "print (\"storyref dropped\")\n",
    "\n",
    "\n",
    "#Create table storyref\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE storyref(\n",
    "    storya_id INT NOT NULL,\n",
    "    storyb_id INT NOT NULL,\n",
    "    PRIMARY KEY (storya_id, storyb_id),\n",
    "    FOREIGN KEY (storya_id) REFERENCES story(story_id) ON UPDATE CASCADE,\n",
    "    FOREIGN KEY (storyb_id) REFERENCES story(story_id) ON UPDATE CASCADE\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"storyref created\")\n",
    "\n",
    "print(\"storyref empty\")\n",
    "\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "print(\"connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6fa0cc",
   "metadata": {},
   "source": [
    "## Story typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8bba6803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stype dropped\n",
      "stype created\n",
      "styping dropped\n",
      "styping created\n",
      "styping empty\n",
      "connection closed\n"
     ]
    }
   ],
   "source": [
    "#Connect to postgres\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS stype CASCADE\")\n",
    "print (\"stype dropped\")\n",
    "\n",
    "\n",
    "#Create table theme\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE stype(\n",
    "    stype_name text NOT NULL,\n",
    "    stype_description text,\n",
    "    stype_id serial PRIMARY KEY\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"stype created\")\n",
    "\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS styping\")\n",
    "print (\"styping dropped\")\n",
    "\n",
    "#Create table theming\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE styping(\n",
    "    story_id INT NOT NULL,\n",
    "    stype_id INT NOT NULL,\n",
    "    PRIMARY KEY (story_id, stype_id),\n",
    "    FOREIGN KEY (story_id) REFERENCES story(story_id) ON UPDATE CASCADE,\n",
    "    FOREIGN KEY (stype_id) REFERENCES stype(stype_id) ON UPDATE CASCADE\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"styping created\")\n",
    "\n",
    "print(\"styping empty\")\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "print(\"connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4790f49",
   "metadata": {},
   "source": [
    "## Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ac92015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sinstance dropped\n",
      "sinstance created\n",
      "instances pre-loaded\n",
      "[(1, datetime.date(1900, 1, 1), datetime.date(1900, 1, 1), 'na', '', None, None, 'Rua do Garrido (no bairro do Alto do Pina, freguesia do Areeiro); Freguesia de Areeiro, Freguesia da Penha de França', 1), (2, datetime.date(2020, 3, 1), datetime.date(1900, 1, 1), 'ongoing', 'COVID', None, None, 'Mercearia Castanheira, Travessa do Terreiro do Trigo, 5, Alfama, Lisboa', 2), (3, datetime.date(2020, 3, 1), datetime.date(1900, 1, 1), 'ongoing', 'COVID', None, None, 'freguesia de Alvalade; Isco padaria; ', 3), (4, datetime.date(2016, 1, 1), datetime.date(1900, 1, 1), 'ongoing', '2016-present', None, None, 'bairro de Mouraria, Rua dos Lagares', 4), (5, datetime.date(2021, 1, 19), datetime.date(2021, 1, 19), 'concrete', '19-Jan', None, None, 'Rua da Cruz da Carreira', 5), (6, datetime.date(2020, 3, 1), datetime.date(1900, 1, 1), 'ongoing', 'March 2020 - current', None, None, 'Coletivo Sirigaita, 12F da Rua dos Anjos', 6), (7, datetime.date(2020, 2, 1), datetime.date(1900, 1, 1), 'ongoing', 'Feb 2020 - current', None, None, 'Mercado de Benfica', 7), (8, datetime.date(2021, 3, 5), datetime.date(2021, 10, 5), 'predicted', '3 March 2021 to 5 October 2021', None, None, 'Pavilhão desportivo do bairro santos ao rego; ciclovia  Avenida de Berna', 8)]\n",
      "connection closed\n"
     ]
    }
   ],
   "source": [
    "#Connect to postgres\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS sinstance CASCADE\")\n",
    "print (\"sinstance dropped\")\n",
    "\n",
    "#Create table sistance. REQUIRES REFERENCE TO GAZETTEERS\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE sinstance(\n",
    "    story_id INT NOT NULL,\n",
    "    t_begin DATE,\n",
    "    t_end DATE,\n",
    "    t_type text,\n",
    "    t_desc text,\n",
    "    place_type INT,\n",
    "    place_id INT,\n",
    "    place_desc text,\n",
    "    sistance_id serial PRIMARY KEY,\n",
    "    FOREIGN KEY (story_id) REFERENCES story(story_id) ON UPDATE CASCADE\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"sinstance created\")\n",
    "\n",
    "#Distribute instances\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO sinstance(story_id, t_begin, t_end, t_type, t_desc, place_desc)\n",
    "    SELECT id, t_begin, t_end, t_type, temporal, spatial\n",
    "    FROM mensagem_stories\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"instances pre-loaded\")\n",
    "\n",
    "cur.execute('SELECT * FROM sinstance')\n",
    "all = cur.fetchall()\n",
    "print(all)\n",
    "\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "print(\"connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0e4f86",
   "metadata": {},
   "source": [
    "## Import GeoNames into Postgres\n",
    "https://gist.github.com/EspadaV8/1357237/25a81f06fd1d04b54cdda35a53f359c45aefce6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cd13ae30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraneous files removed\n",
      "Beginning GEONAMES PT download with wget module\n",
      "100% [##########################################################################]           1M / 1MGeonames PT unzipped\n",
      "Geonames PT txt and zip renamed\n",
      "Beginning ALTNAMES PT download with wget module\n",
      "100% [############################################################################]     201K / 201KDownload Alternate Names PT complete\n",
      "Altnames unzipped\n",
      "Altnames PT txt and zip renamed\n",
      "Beginning Postcodes PT download with wget module\n",
      "100% [##########################################################################]           1M / 1Mpostcodes PT unzipped\n",
      "Postcodes PT txt and zip renamed\n",
      "Beginning ISO Language Codes download with wget module\n",
      "100% [############################################################################]     126K / 126KDownload Language Codes complete\n",
      "Beginning Feature Codes download with wget module\n",
      "100% [##############################################################################]     56K / 56KDownload Feature Codes complete\n",
      "Beginning Admin1 Codes download with wget module\n",
      "100% [############################################################################]     134K / 134KDownload Admin1 Codes complete\n",
      "Beginning Admin2 Codes download with wget module\n",
      "100% [##########################################################################]           2M / 2MDownload Admin2 Codes complete\n",
      "GREAT SUCCESS!!\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#tidy up the folder structure\n",
    "#os.remove(r\"C:\\mcsig_git\\data_load\\PT.zip\")\n",
    "#os.remove(r\"C:\\mcsig_git\\data_load\\geonamesPT.zip\")\n",
    "#os.remove(r\"C:\\mcsig_git\\data_load\\altPT.zip\")\n",
    "#os.remove(r\"C:\\mcsig_git\\data_load\\zipPT.zip\")\n",
    "#os.remove(r\"C:\\mcsig_git\\data_load\\zipAll.zip\")\n",
    "shutil.rmtree(\"C:\\mcsig_git\\data_load\\pt\")\n",
    "os.mkdir(\"pt\")\n",
    "print('extraneous files removed')\n",
    "\n",
    "#download geonamesPT\n",
    "print('Beginning GEONAMES PT download with wget module')\n",
    "url = 'http://download.geonames.org/export/dump/PT.zip'\n",
    "wget.download(url, 'C:\\mcsig_git\\data_load')\n",
    "import zipfile\n",
    "with zipfile.ZipFile('C:\\mcsig_git\\data_load\\PT.zip', 'r') as zip_ref:\n",
    "                     zip_ref.extractall('C:\\mcsig_git\\data_load\\pt')\n",
    "print('Geonames PT unzipped')\n",
    "os.rename(r'C:\\mcsig_git\\data_load\\PT.zip',r'C:\\mcsig_git\\data_load\\geonamesPT.zip')\n",
    "os.rename(r'C:\\mcsig_git\\data_load\\pt\\PT.txt',r'C:\\mcsig_git\\data_load\\pt\\geonamesPT.txt')\n",
    "print('Geonames PT txt and zip renamed')\n",
    "\n",
    "\n",
    "#download alternatenamesPT\n",
    "print('Beginning ALTNAMES PT download with wget module')\n",
    "url = 'http://download.geonames.org/export/dump/alternatenames/PT.zip'\n",
    "wget.download(url, 'C:\\mcsig_git\\data_load')\n",
    "print('Download Alternate Names PT complete')\n",
    "with zipfile.ZipFile('C:\\mcsig_git\\data_load\\PT.zip', 'r') as zip_ref:\n",
    "                     zip_ref.extractall('C:\\mcsig_git\\data_load\\pt')\n",
    "print('Altnames unzipped')\n",
    "os.rename(r'C:\\mcsig_git\\data_load\\PT.zip',r'C:\\mcsig_git\\data_load\\altPT.zip')\n",
    "os.rename(r'C:\\mcsig_git\\data_load\\pt\\PT.txt',r'C:\\mcsig_git\\data_load\\pt\\altPT.txt')\n",
    "print('Altnames PT txt and zip renamed')\n",
    "\n",
    "#download postcodesPT\n",
    "print('Beginning Postcodes PT download with wget module')\n",
    "url = 'http://download.geonames.org/export/zip/PT.zip'\n",
    "wget.download(url, 'C:\\mcsig_git\\data_load')\n",
    "import zipfile\n",
    "with zipfile.ZipFile('C:\\mcsig_git\\data_load\\PT.zip', 'r') as zip_ref:\n",
    "                     zip_ref.extractall('C:\\mcsig_git\\data_load\\pt')\n",
    "print('postcodes PT unzipped')\n",
    "os.rename(r'C:\\mcsig_git\\data_load\\PT.zip',r'C:\\mcsig_git\\data_load\\zipPT.zip')\n",
    "os.rename(r'C:\\mcsig_git\\data_load\\pt\\PT.txt',r'C:\\mcsig_git\\data_load\\pt\\zipPT.txt')\n",
    "print('Postcodes PT txt and zip renamed')\n",
    "\n",
    "#download postcodes all\n",
    "#print('Beginning Postcodes all download with wget module')\n",
    "#url = 'http://download.geonames.org/export/zip/allCountries.zip'\n",
    "#wget.download(url, 'C:\\mcsig_git\\data_load')\n",
    "#import zipfile\n",
    "#with zipfile.ZipFile(r'C:\\mcsig_git\\data_load\\allCountries.zip', 'r') as zip_ref:\n",
    "#                     zip_ref.extractall('C:\\mcsig_git\\data_load\\pt')\n",
    "#print('postcodes all unzipped')\n",
    "#os.rename(r'C:\\mcsig_git\\data_load\\allCountries.zip',r'C:\\mcsig_git\\data_load\\zipAll.zip')\n",
    "#os.rename(r'C:\\mcsig_git\\data_load\\pt\\allCountries.txt',r'C:\\mcsig_git\\data_load\\pt\\zipAll.txt')\n",
    "#print('Postcodes ALL txt and zip renamed')\n",
    "\n",
    "#download iso-language codes\n",
    "print('Beginning ISO Language Codes download with wget module')\n",
    "url = 'http://download.geonames.org/export/dump/iso-languagecodes.txt'\n",
    "wget.download(url, 'C:\\mcsig_git\\data_load\\pt')\n",
    "print('Download Language Codes complete')\n",
    "\n",
    "#download featurecode\n",
    "print('Beginning Feature Codes download with wget module')\n",
    "url = 'http://download.geonames.org/export/dump/featureCodes_en.txt'\n",
    "wget.download(url, 'C:\\mcsig_git\\data_load\\pt')\n",
    "print('Download Feature Codes complete')\n",
    "\n",
    "#download admin1codes\n",
    "print('Beginning Admin1 Codes download with wget module')\n",
    "url = 'http://download.geonames.org/export/dump/admin1CodesASCII.txt'\n",
    "wget.download(url, 'C:\\mcsig_git\\data_load\\pt')\n",
    "print('Download Admin1 Codes complete')\n",
    "\n",
    "#download admin2codes\n",
    "print('Beginning Admin2 Codes download with wget module')\n",
    "url = 'http://download.geonames.org/export/dump/admin2Codes.txt'\n",
    "wget.download(url, 'C:\\mcsig_git\\data_load\\pt')\n",
    "print('Download Admin2 Codes complete')\n",
    "\n",
    "print('GREAT SUCCESS!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b828880e",
   "metadata": {},
   "source": [
    "## Must associate spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9675e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection open\n",
      "geoname dropped\n",
      "geonames created\n",
      "Geonames loaded\n",
      "alternatename dropped\n",
      "alternatenames created\n",
      "alternatename loaded\n",
      "iso_languagecodes dropped\n",
      "iso_languagecodes created\n",
      "iso_languagecodes loaded\n",
      "admin1CodesAscii dropped\n",
      "admin1CodesAscii created\n",
      "admin1CodesAscii loaded\n",
      "admin2CodesAscii dropped\n",
      "admin2CodesAscii created\n",
      "admin2CodesAscii loaded\n",
      "featureCodes dropped\n",
      "featureCodes created\n",
      "featureCodes loaded\n",
      "postalCodes dropped\n",
      "postalCodes created\n",
      "postalCodes loaded\n",
      "alternatename indexed on geonameid\n",
      "GREAT SUCCESS!!!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "print(\"Connection open\")\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS geoname CASCADE\")\n",
    "print (\"geoname dropped\")\n",
    "\n",
    "#Create table if exists\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE geoname(\n",
    "    geoname_id int,\n",
    "    name varchar(200),\n",
    "    asciiname varchar(200),\n",
    "    alternatenames varchar(10000),\n",
    "    latitude float,\n",
    "    longitude float,\n",
    "    fclass char(1),\n",
    "    fcode varchar(10),\n",
    "    countrycode char(2),\n",
    "    cc2 varchar(200),\n",
    "    admin1 varchar(20),\n",
    "    admin2 varchar(80),\n",
    "    admin3 varchar(20),\n",
    "    admin4 varchar(20),\n",
    "    population bigint,\n",
    "    elevation bigint,\n",
    "    gtopo30 int,\n",
    "    timezone varchar(40),\n",
    "    moddate date,\n",
    "    PRIMARY KEY (geoname_id)\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"geonames created\")\n",
    "\n",
    "with open(r'C:\\mcsig_git\\data_load\\pt\\geonamesPT.txt', 'r', encoding='utf-8') as f:\n",
    "#    next(f) #skip header row\n",
    "    cur.copy_from(f, 'geoname', sep=\"\\t\", null=\"\")\n",
    "conn.commit()\n",
    "print(\"Geonames loaded\")\n",
    "\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS alternatename CASCADE\")\n",
    "print (\"alternatename dropped\")\n",
    "\n",
    "#Create table if exists\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE alternatename(\n",
    "    alternatename_id int,\n",
    "    geonameid int,\n",
    "    isoLanguage varchar(7),\n",
    "    alternateName varchar(400),\n",
    "    isPreferredName boolean,\n",
    "    isShortName boolean,\n",
    "    isColloquial boolean,\n",
    "    isHistoric boolean,\n",
    "    fromPeriod text,\n",
    "    toPeriod text,\n",
    "    PRIMARY KEY (alternatename_id),\n",
    "    FOREIGN KEY (geonameid) REFERENCES geoname(geoname_id) ON UPDATE CASCADE\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"alternatenames created\")\n",
    "\n",
    "with open(r'C:\\mcsig_git\\data_load\\pt\\altPT.txt', 'r', encoding='utf-8') as f:\n",
    "#    next(f) #skip header row\n",
    "    cur.copy_from(f, 'alternatename', sep=\"\\t\", null=\"\")\n",
    "conn.commit()\n",
    "print(\"alternatename loaded\")\n",
    "\n",
    "\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS iso_languagecodes CASCADE\")\n",
    "print (\"iso_languagecodes dropped\")\n",
    "\n",
    "#Create table if exists\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE iso_languagecodes(\n",
    "    iso_639_3 char(4),\n",
    "    iso_639_2 VARCHAR(50),\n",
    "    iso_639_1 VARCHAR(50),\n",
    "    language_name VARCHAR(200)\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"iso_languagecodes created\")\n",
    "\n",
    "with open(r'C:\\mcsig_git\\data_load\\pt\\iso-languagecodes.txt', 'r', encoding='utf-8') as f:\n",
    "    next(f) #skip header row\n",
    "    cur.copy_from(f, 'iso_languagecodes', sep=\"\\t\", null=\"\")\n",
    "conn.commit()\n",
    "print(\"iso_languagecodes loaded\")\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS admin1CodesAscii CASCADE\")\n",
    "print (\"admin1CodesAscii dropped\")\n",
    "\n",
    "#Create table if exists\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE admin1CodesAscii(\n",
    "    code CHAR(20),\n",
    "    name TEXT,\n",
    "    nameAscii TEXT,\n",
    "    geonameid int\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"admin1CodesAscii created\")\n",
    "\n",
    "with open(r'C:\\mcsig_git\\data_load\\pt\\admin1CodesASCII.txt', 'r', encoding='utf-8') as f:\n",
    "#    next(f) #skip header row\n",
    "    cur.copy_from(f, 'admin1CodesAscii', sep=\"\\t\", null=\"\")\n",
    "conn.commit()\n",
    "print(\"admin1CodesAscii loaded\")\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS admin2CodesAscii CASCADE\")\n",
    "print (\"admin2CodesAscii dropped\")\n",
    "\n",
    "#Create table if exists\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE admin2CodesAscii(\n",
    "    code CHAR(80),\n",
    "    name TEXT,\n",
    "    nameAscii TEXT,\n",
    "    geonameid int\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"admin2CodesAscii created\")\n",
    "\n",
    "with open(r'C:\\mcsig_git\\data_load\\pt\\admin2Codes.txt', 'r', encoding='utf-8') as f:\n",
    "#    next(f) #skip header row\n",
    "    cur.copy_from(f, 'admin2CodesAscii', sep=\"\\t\", null=\"\")\n",
    "conn.commit()\n",
    "print(\"admin2CodesAscii loaded\")\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS featureCodes CASCADE\")\n",
    "print (\"featureCodes dropped\")\n",
    "\n",
    "#Create table if exists\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE featureCodes(\n",
    "    code CHAR(7),\n",
    "    name varchar(200),\n",
    "    description TEXT\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"featureCodes created\")\n",
    "\n",
    "with open(r'C:\\mcsig_git\\data_load\\pt\\featureCodes_en.txt', 'r', encoding='utf-8') as f:\n",
    "#    next(f) #skip header row\n",
    "    cur.copy_from(f, 'featureCodes', sep=\"\\t\", null=\"\")\n",
    "conn.commit()\n",
    "print(\"featureCodes loaded\")\n",
    "\n",
    "\n",
    "#Drop table if already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS postalCodes CASCADE\")\n",
    "print (\"postalCodes dropped\")\n",
    "\n",
    "#Create table if exists\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE postalCodes(\n",
    "    countrycode char(2),\n",
    "    postalcode varchar(20),\n",
    "    placename varchar(180),\n",
    "    admin1name varchar(100),\n",
    "    admin1code varchar(20),\n",
    "    admin2name varchar(100),\n",
    "    admin2code varchar(20),\n",
    "    admin3name varchar(100),\n",
    "    admin3code varchar(20),\n",
    "    latitude float,\n",
    "    longitude float,\n",
    "    accuracy smallint\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"postalCodes created\")\n",
    "\n",
    "with open(r'C:\\mcsig_git\\data_load\\pt\\zipPT.txt', 'r', encoding='utf-8') as f:\n",
    "#    next(f) #skip header row\n",
    "    cur.copy_from(f, 'postalCodes', sep=\"\\t\", null=\"\")\n",
    "conn.commit()\n",
    "print(\"postalCodes loaded\")\n",
    "\n",
    "cur.execute(\"CREATE INDEX index_alternatename_geonameid ON alternatename USING hash (geonameid)\")\n",
    "conn.commit()\n",
    "print(\"alternatename indexed on geonameid\")\n",
    "\n",
    "print(\"GREAT SUCCESS!!!\")\n",
    "\n",
    "#Closing the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2fe13f",
   "metadata": {},
   "source": [
    "## Testing ogr import of geonamesPT\n",
    "Incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ac7afb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory is  C:\\mcsig_git\\data_load\\pt\n",
      "current working directory is  C:\\\n",
      "current working directory is  C:\\\n",
      "Connection open\n",
      "Successfully loaded geonamesPT\n",
      "Great success!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning 1: Value '563.0' of field geonamesPT.ELEVATION parsed incompletely to integer 563.\n",
      "Warning 1: Invalid value type found in record 1309 for field ELEVATION. This warning will no longer be emitted\n",
      "Warning 1: Value '1027.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1027.\n",
      "Warning 1: Value '1862.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1862.\n",
      "Warning 1: Value '70.0' of field geonamesPT.ELEVATION parsed incompletely to integer 70.\n",
      "Warning 1: Value '94.0' of field geonamesPT.ELEVATION parsed incompletely to integer 94.\n",
      "Warning 1: Value '346.0' of field geonamesPT.ELEVATION parsed incompletely to integer 346.\n",
      "Warning 1: Value '666.0' of field geonamesPT.ELEVATION parsed incompletely to integer 666.\n",
      "Warning 1: Value '300.0' of field geonamesPT.ELEVATION parsed incompletely to integer 300.\n",
      "Warning 1: Value '902.0' of field geonamesPT.ELEVATION parsed incompletely to integer 902.\n",
      "Warning 1: Value '528.0' of field geonamesPT.ELEVATION parsed incompletely to integer 528.\n",
      "Warning 1: Value '1818.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1818.\n",
      "Warning 1: Value '550.0' of field geonamesPT.ELEVATION parsed incompletely to integer 550.\n",
      "Warning 1: Value '900.0' of field geonamesPT.ELEVATION parsed incompletely to integer 900.\n",
      "Warning 1: Value '440.0' of field geonamesPT.ELEVATION parsed incompletely to integer 440.\n",
      "Warning 1: Value '1025.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1025.\n",
      "Warning 1: Value '1315.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1315.\n",
      "Warning 1: Value '409.0' of field geonamesPT.ELEVATION parsed incompletely to integer 409.\n",
      "Warning 1: Value '424.0' of field geonamesPT.ELEVATION parsed incompletely to integer 424.\n",
      "Warning 1: Value '366.0' of field geonamesPT.ELEVATION parsed incompletely to integer 366.\n",
      "Warning 1: Value '416.0' of field geonamesPT.ELEVATION parsed incompletely to integer 416.\n",
      "Warning 1: Value '843.0' of field geonamesPT.ELEVATION parsed incompletely to integer 843.\n",
      "Warning 1: Value '183.0' of field geonamesPT.ELEVATION parsed incompletely to integer 183.\n",
      "Warning 1: Value '1278.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1278.\n",
      "Warning 1: Value '539.0' of field geonamesPT.ELEVATION parsed incompletely to integer 539.\n",
      "Warning 1: Value '385.0' of field geonamesPT.ELEVATION parsed incompletely to integer 385.\n",
      "Warning 1: Value '1381.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1381.\n",
      "Warning 1: Value '1203.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1203.\n",
      "Warning 1: Value '1415.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1415.\n",
      "Warning 1: Value '2592.0' of field geonamesPT.ELEVATION parsed incompletely to integer 2592.\n",
      "Warning 1: Value '1077.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1077.\n",
      "Warning 1: Value '318.0' of field geonamesPT.ELEVATION parsed incompletely to integer 318.\n",
      "Warning 1: Value '1134.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1134.\n",
      "Warning 1: Value '1993.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1993.\n",
      "Warning 1: Value '205.0' of field geonamesPT.ELEVATION parsed incompletely to integer 205.\n",
      "Warning 1: Value '324.0' of field geonamesPT.ELEVATION parsed incompletely to integer 324.\n",
      "Warning 1: Value '518.0' of field geonamesPT.ELEVATION parsed incompletely to integer 518.\n",
      "Warning 1: Value '370.0' of field geonamesPT.ELEVATION parsed incompletely to integer 370.\n",
      "Warning 1: Value '1362.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1362.\n",
      "Warning 1: Value '1330.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1330.\n",
      "Warning 1: Value '410.0' of field geonamesPT.ELEVATION parsed incompletely to integer 410.\n",
      "Warning 1: Value '1103.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1103.\n",
      "Warning 1: Value '497.0' of field geonamesPT.ELEVATION parsed incompletely to integer 497.\n",
      "Warning 1: Value '1021.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1021.\n",
      "Warning 1: Value '2351.0' of field geonamesPT.ELEVATION parsed incompletely to integer 2351.\n",
      "Warning 1: Value '1043.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1043.\n",
      "Warning 1: Value '400.0' of field geonamesPT.ELEVATION parsed incompletely to integer 400.\n",
      "Warning 1: Value '846.0' of field geonamesPT.ELEVATION parsed incompletely to integer 846.\n",
      "Warning 1: Value '813.0' of field geonamesPT.ELEVATION parsed incompletely to integer 813.\n",
      "Warning 1: Value '205.0' of field geonamesPT.ELEVATION parsed incompletely to integer 205.\n",
      "Warning 1: Value '586.0' of field geonamesPT.ELEVATION parsed incompletely to integer 586.\n",
      "Warning 1: Value '10.0' of field geonamesPT.ELEVATION parsed incompletely to integer 10.\n",
      "Warning 1: Value '677.0' of field geonamesPT.ELEVATION parsed incompletely to integer 677.\n",
      "Warning 1: Value '207.0' of field geonamesPT.ELEVATION parsed incompletely to integer 207.\n",
      "Warning 1: Value '280.0' of field geonamesPT.ELEVATION parsed incompletely to integer 280.\n",
      "Warning 1: Value '6.0' of field geonamesPT.ELEVATION parsed incompletely to integer 6.\n",
      "Warning 1: Value '114.0' of field geonamesPT.ELEVATION parsed incompletely to integer 114.\n",
      "Warning 1: Value '62.0' of field geonamesPT.ELEVATION parsed incompletely to integer 62.\n",
      "Warning 1: Value '219.0' of field geonamesPT.ELEVATION parsed incompletely to integer 219.\n",
      "Warning 1: Value '393.0' of field geonamesPT.ELEVATION parsed incompletely to integer 393.\n",
      "Warning 1: Value '73.0' of field geonamesPT.ELEVATION parsed incompletely to integer 73.\n",
      "Warning 1: Value '113.0' of field geonamesPT.ELEVATION parsed incompletely to integer 113.\n",
      "Warning 1: Value '101.0' of field geonamesPT.ELEVATION parsed incompletely to integer 101.\n",
      "Warning 1: Value '92.0' of field geonamesPT.ELEVATION parsed incompletely to integer 92.\n",
      "Warning 1: Value '874.0' of field geonamesPT.ELEVATION parsed incompletely to integer 874.\n",
      "Warning 1: Value '291.0' of field geonamesPT.ELEVATION parsed incompletely to integer 291.\n",
      "Warning 1: Value '409.0' of field geonamesPT.ELEVATION parsed incompletely to integer 409.\n",
      "Warning 1: Value '657.0' of field geonamesPT.ELEVATION parsed incompletely to integer 657.\n",
      "Warning 1: Value '564.0' of field geonamesPT.ELEVATION parsed incompletely to integer 564.\n",
      "Warning 1: Value '338.0' of field geonamesPT.ELEVATION parsed incompletely to integer 338.\n",
      "Warning 1: Value '490.0' of field geonamesPT.ELEVATION parsed incompletely to integer 490.\n",
      "Warning 1: Value '5.0' of field geonamesPT.ELEVATION parsed incompletely to integer 5.\n",
      "Warning 1: Value '101.0' of field geonamesPT.ELEVATION parsed incompletely to integer 101.\n",
      "Warning 1: Value '683.0' of field geonamesPT.ELEVATION parsed incompletely to integer 683.\n",
      "Warning 1: Value '193.0' of field geonamesPT.ELEVATION parsed incompletely to integer 193.\n",
      "Warning 1: Value '34.0' of field geonamesPT.ELEVATION parsed incompletely to integer 34.\n",
      "Warning 1: Value '7.0' of field geonamesPT.ELEVATION parsed incompletely to integer 7.\n",
      "Warning 1: Value '35.0' of field geonamesPT.ELEVATION parsed incompletely to integer 35.\n",
      "Warning 1: Value '54.0' of field geonamesPT.ELEVATION parsed incompletely to integer 54.\n",
      "Warning 1: Value '57.0' of field geonamesPT.ELEVATION parsed incompletely to integer 57.\n",
      "Warning 1: Value '14.0' of field geonamesPT.ELEVATION parsed incompletely to integer 14.\n",
      "Warning 1: Value '17.0' of field geonamesPT.ELEVATION parsed incompletely to integer 17.\n",
      "Warning 1: Value '78.0' of field geonamesPT.ELEVATION parsed incompletely to integer 78.\n",
      "Warning 1: Value '69.0' of field geonamesPT.ELEVATION parsed incompletely to integer 69.\n",
      "Warning 1: Value '103.0' of field geonamesPT.ELEVATION parsed incompletely to integer 103.\n",
      "Warning 1: Value '134.0' of field geonamesPT.ELEVATION parsed incompletely to integer 134.\n",
      "Warning 1: Value '81.0' of field geonamesPT.ELEVATION parsed incompletely to integer 81.\n",
      "Warning 1: Value '550.0' of field geonamesPT.ELEVATION parsed incompletely to integer 550.\n",
      "Warning 1: Value '93.0' of field geonamesPT.ELEVATION parsed incompletely to integer 93.\n",
      "Warning 1: Value '59.0' of field geonamesPT.ELEVATION parsed incompletely to integer 59.\n",
      "Warning 1: Value '113.0' of field geonamesPT.ELEVATION parsed incompletely to integer 113.\n",
      "Warning 1: Value '2351.0' of field geonamesPT.ELEVATION parsed incompletely to integer 2351.\n",
      "Warning 1: Value '2.0' of field geonamesPT.ELEVATION parsed incompletely to integer 2.\n",
      "Warning 1: Value '10.0' of field geonamesPT.ELEVATION parsed incompletely to integer 10.\n",
      "Warning 1: Value '240.0' of field geonamesPT.ELEVATION parsed incompletely to integer 240.\n",
      "Warning 1: Value '453.0' of field geonamesPT.ELEVATION parsed incompletely to integer 453.\n",
      "Warning 1: Value '265.0' of field geonamesPT.ELEVATION parsed incompletely to integer 265.\n",
      "Warning 1: Value '250.0' of field geonamesPT.ELEVATION parsed incompletely to integer 250.\n",
      "Warning 1: Value '240.0' of field geonamesPT.ELEVATION parsed incompletely to integer 240.\n",
      "Warning 1: Value '230.0' of field geonamesPT.ELEVATION parsed incompletely to integer 230.\n",
      "Warning 1: Value '220.0' of field geonamesPT.ELEVATION parsed incompletely to integer 220.\n",
      "Warning 1: Value '220.0' of field geonamesPT.ELEVATION parsed incompletely to integer 220.\n",
      "Warning 1: Value '220.0' of field geonamesPT.ELEVATION parsed incompletely to integer 220.\n",
      "Warning 1: Value '220.0' of field geonamesPT.ELEVATION parsed incompletely to integer 220.\n",
      "Warning 1: Value '220.0' of field geonamesPT.ELEVATION parsed incompletely to integer 220.\n",
      "Warning 1: Value '1025.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1025.\n",
      "Warning 1: Value '1330.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1330.\n",
      "Warning 1: Value '1157.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1157.\n",
      "Warning 1: Value '1201.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1201.\n",
      "Warning 1: Value '26.0' of field geonamesPT.ELEVATION parsed incompletely to integer 26.\n",
      "Warning 1: Value '1299.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1299.\n",
      "Warning 1: Value '2.0' of field geonamesPT.ELEVATION parsed incompletely to integer 2.\n",
      "Warning 1: Value '2.0' of field geonamesPT.ELEVATION parsed incompletely to integer 2.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '1.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1.\n",
      "Warning 1: Value '1.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1.\n",
      "Warning 1: Value '2.0' of field geonamesPT.ELEVATION parsed incompletely to integer 2.\n",
      "Warning 1: Value '5.0' of field geonamesPT.ELEVATION parsed incompletely to integer 5.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '1153.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1153.\n",
      "Warning 1: Value '1005.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1005.\n",
      "Warning 1: Value '1545.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1545.\n",
      "Warning 1: Value '102.0' of field geonamesPT.ELEVATION parsed incompletely to integer 102.\n",
      "Warning 1: Value '320.0' of field geonamesPT.ELEVATION parsed incompletely to integer 320.\n",
      "Warning 1: Value '200.0' of field geonamesPT.ELEVATION parsed incompletely to integer 200.\n",
      "Warning 1: Value '236.0' of field geonamesPT.ELEVATION parsed incompletely to integer 236.\n",
      "Warning 1: Value '192.0' of field geonamesPT.ELEVATION parsed incompletely to integer 192.\n",
      "Warning 1: Value '328.0' of field geonamesPT.ELEVATION parsed incompletely to integer 328.\n",
      "Warning 1: Value '350.0' of field geonamesPT.ELEVATION parsed incompletely to integer 350.\n",
      "Warning 1: Value '40.0' of field geonamesPT.ELEVATION parsed incompletely to integer 40.\n",
      "Warning 1: Value '410.0' of field geonamesPT.ELEVATION parsed incompletely to integer 410.\n",
      "Warning 1: Value '1546.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1546.\n",
      "Warning 1: Value '202.0' of field geonamesPT.ELEVATION parsed incompletely to integer 202.\n",
      "Warning 1: Value '257.0' of field geonamesPT.ELEVATION parsed incompletely to integer 257.\n",
      "Warning 1: Value '519.0' of field geonamesPT.ELEVATION parsed incompletely to integer 519.\n",
      "Warning 1: Value '532.0' of field geonamesPT.ELEVATION parsed incompletely to integer 532.\n",
      "Warning 1: Value '519.0' of field geonamesPT.ELEVATION parsed incompletely to integer 519.\n",
      "Warning 1: Value '63.0' of field geonamesPT.ELEVATION parsed incompletely to integer 63.\n",
      "Warning 1: Value '219.0' of field geonamesPT.ELEVATION parsed incompletely to integer 219.\n",
      "Warning 1: Value '150.0' of field geonamesPT.ELEVATION parsed incompletely to integer 150.\n",
      "Warning 1: Value '4.0' of field geonamesPT.ELEVATION parsed incompletely to integer 4.\n",
      "Warning 1: Value '4.0' of field geonamesPT.ELEVATION parsed incompletely to integer 4.\n",
      "Warning 1: Value '4.0' of field geonamesPT.ELEVATION parsed incompletely to integer 4.\n",
      "Warning 1: Value '10.0' of field geonamesPT.ELEVATION parsed incompletely to integer 10.\n",
      "Warning 1: Value '10.0' of field geonamesPT.ELEVATION parsed incompletely to integer 10.\n",
      "Warning 1: Value '10.0' of field geonamesPT.ELEVATION parsed incompletely to integer 10.\n",
      "Warning 1: Value '10.0' of field geonamesPT.ELEVATION parsed incompletely to integer 10.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '150.0' of field geonamesPT.ELEVATION parsed incompletely to integer 150.\n",
      "Warning 1: Value '150.0' of field geonamesPT.ELEVATION parsed incompletely to integer 150.\n",
      "Warning 1: Value '150.0' of field geonamesPT.ELEVATION parsed incompletely to integer 150.\n",
      "Warning 1: Value '71.0' of field geonamesPT.ELEVATION parsed incompletely to integer 71.\n",
      "Warning 1: Value '1054.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1054.\n",
      "Warning 1: Value '1851.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1851.\n",
      "Warning 1: Value '413.0' of field geonamesPT.ELEVATION parsed incompletely to integer 413.\n",
      "Warning 1: Value '58.0' of field geonamesPT.ELEVATION parsed incompletely to integer 58.\n",
      "Warning 1: Value '528.0' of field geonamesPT.ELEVATION parsed incompletely to integer 528.\n",
      "Warning 1: Value '360.0' of field geonamesPT.ELEVATION parsed incompletely to integer 360.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '1211.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1211.\n",
      "Warning 1: Value '870.0' of field geonamesPT.ELEVATION parsed incompletely to integer 870.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '5.0' of field geonamesPT.ELEVATION parsed incompletely to integer 5.\n",
      "Warning 1: Value '1199.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1199.\n",
      "Warning 1: Value '1227.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1227.\n",
      "Warning 1: Value '1416.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1416.\n",
      "Warning 1: Value '1023.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1023.\n",
      "Warning 1: Value '873.0' of field geonamesPT.ELEVATION parsed incompletely to integer 873.\n",
      "Warning 1: Value '718.0' of field geonamesPT.ELEVATION parsed incompletely to integer 718.\n",
      "Warning 1: Value '883.0' of field geonamesPT.ELEVATION parsed incompletely to integer 883.\n",
      "Warning 1: Value '831.0' of field geonamesPT.ELEVATION parsed incompletely to integer 831.\n",
      "Warning 1: Value '1232.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1232.\n",
      "Warning 1: Value '1365.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1365.\n",
      "Warning 1: Value '725.0' of field geonamesPT.ELEVATION parsed incompletely to integer 725.\n",
      "Warning 1: Value '501.0' of field geonamesPT.ELEVATION parsed incompletely to integer 501.\n",
      "Warning 1: Value '312.0' of field geonamesPT.ELEVATION parsed incompletely to integer 312.\n",
      "Warning 1: Value '19.0' of field geonamesPT.ELEVATION parsed incompletely to integer 19.\n",
      "Warning 1: Value '6.0' of field geonamesPT.ELEVATION parsed incompletely to integer 6.\n",
      "Warning 1: Value '135.0' of field geonamesPT.ELEVATION parsed incompletely to integer 135.\n",
      "Warning 1: Value '99.0' of field geonamesPT.ELEVATION parsed incompletely to integer 99.\n",
      "Warning 1: Value '838.0' of field geonamesPT.ELEVATION parsed incompletely to integer 838.\n",
      "Warning 1: Value '351.0' of field geonamesPT.ELEVATION parsed incompletely to integer 351.\n",
      "Warning 1: Value '215.0' of field geonamesPT.ELEVATION parsed incompletely to integer 215.\n",
      "Warning 1: Value '4.0' of field geonamesPT.ELEVATION parsed incompletely to integer 4.\n",
      "Warning 1: Value '74.0' of field geonamesPT.ELEVATION parsed incompletely to integer 74.\n",
      "Warning 1: Value '212.0' of field geonamesPT.ELEVATION parsed incompletely to integer 212.\n",
      "Warning 1: Value '216.0' of field geonamesPT.ELEVATION parsed incompletely to integer 216.\n",
      "Warning 1: Value '66.0' of field geonamesPT.ELEVATION parsed incompletely to integer 66.\n",
      "Warning 1: Value '276.0' of field geonamesPT.ELEVATION parsed incompletely to integer 276.\n",
      "Warning 1: Value '19.0' of field geonamesPT.ELEVATION parsed incompletely to integer 19.\n",
      "Warning 1: Value '234.0' of field geonamesPT.ELEVATION parsed incompletely to integer 234.\n",
      "Warning 1: Value '9.0' of field geonamesPT.ELEVATION parsed incompletely to integer 9.\n",
      "Warning 1: Value '9.0' of field geonamesPT.ELEVATION parsed incompletely to integer 9.\n",
      "Warning 1: Value '14.0' of field geonamesPT.ELEVATION parsed incompletely to integer 14.\n",
      "Warning 1: Value '32.0' of field geonamesPT.ELEVATION parsed incompletely to integer 32.\n",
      "Warning 1: Value '25.0' of field geonamesPT.ELEVATION parsed incompletely to integer 25.\n",
      "Warning 1: Value '12.0' of field geonamesPT.ELEVATION parsed incompletely to integer 12.\n",
      "Warning 1: Value '16.0' of field geonamesPT.ELEVATION parsed incompletely to integer 16.\n",
      "Warning 1: Value '23.0' of field geonamesPT.ELEVATION parsed incompletely to integer 23.\n",
      "Warning 1: Value '63.0' of field geonamesPT.ELEVATION parsed incompletely to integer 63.\n",
      "Warning 1: Value '13.0' of field geonamesPT.ELEVATION parsed incompletely to integer 13.\n",
      "Warning 1: Value '21.0' of field geonamesPT.ELEVATION parsed incompletely to integer 21.\n",
      "Warning 1: Value '784.0' of field geonamesPT.ELEVATION parsed incompletely to integer 784.\n",
      "Warning 1: Value '783.0' of field geonamesPT.ELEVATION parsed incompletely to integer 783.\n",
      "Warning 1: Value '248.0' of field geonamesPT.ELEVATION parsed incompletely to integer 248.\n",
      "Warning 1: Value '19.0' of field geonamesPT.ELEVATION parsed incompletely to integer 19.\n",
      "Warning 1: Value '11.0' of field geonamesPT.ELEVATION parsed incompletely to integer 11.\n",
      "Warning 1: Value '170.0' of field geonamesPT.ELEVATION parsed incompletely to integer 170.\n",
      "Warning 1: Value '224.0' of field geonamesPT.ELEVATION parsed incompletely to integer 224.\n",
      "Warning 1: Value '118.0' of field geonamesPT.ELEVATION parsed incompletely to integer 118.\n",
      "Warning 1: Value '904.0' of field geonamesPT.ELEVATION parsed incompletely to integer 904.\n",
      "Warning 1: Value '1010.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1010.\n",
      "Warning 1: Value '36.0' of field geonamesPT.ELEVATION parsed incompletely to integer 36.\n",
      "Warning 1: Value '122.0' of field geonamesPT.ELEVATION parsed incompletely to integer 122.\n",
      "Warning 1: Value '141.0' of field geonamesPT.ELEVATION parsed incompletely to integer 141.\n",
      "Warning 1: Value '8.0' of field geonamesPT.ELEVATION parsed incompletely to integer 8.\n",
      "Warning 1: Value '184.0' of field geonamesPT.ELEVATION parsed incompletely to integer 184.\n",
      "Warning 1: Value '364.0' of field geonamesPT.ELEVATION parsed incompletely to integer 364.\n",
      "Warning 1: Value '45.0' of field geonamesPT.ELEVATION parsed incompletely to integer 45.\n",
      "Warning 1: Value '26.0' of field geonamesPT.ELEVATION parsed incompletely to integer 26.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '10.0' of field geonamesPT.ELEVATION parsed incompletely to integer 10.\n",
      "Warning 1: Value '9.0' of field geonamesPT.ELEVATION parsed incompletely to integer 9.\n",
      "Warning 1: Value '4.0' of field geonamesPT.ELEVATION parsed incompletely to integer 4.\n",
      "Warning 1: Value '16.0' of field geonamesPT.ELEVATION parsed incompletely to integer 16.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '9.0' of field geonamesPT.ELEVATION parsed incompletely to integer 9.\n",
      "Warning 1: Value '7.0' of field geonamesPT.ELEVATION parsed incompletely to integer 7.\n",
      "Warning 1: Value '6.0' of field geonamesPT.ELEVATION parsed incompletely to integer 6.\n",
      "Warning 1: Value '10.0' of field geonamesPT.ELEVATION parsed incompletely to integer 10.\n",
      "Warning 1: Value '41.0' of field geonamesPT.ELEVATION parsed incompletely to integer 41.\n",
      "Warning 1: Value '61.0' of field geonamesPT.ELEVATION parsed incompletely to integer 61.\n",
      "Warning 1: Value '191.0' of field geonamesPT.ELEVATION parsed incompletely to integer 191.\n",
      "Warning 1: Value '189.0' of field geonamesPT.ELEVATION parsed incompletely to integer 189.\n",
      "Warning 1: Value '112.0' of field geonamesPT.ELEVATION parsed incompletely to integer 112.\n",
      "Warning 1: Value '572.0' of field geonamesPT.ELEVATION parsed incompletely to integer 572.\n",
      "Warning 1: Value '860.0' of field geonamesPT.ELEVATION parsed incompletely to integer 860.\n",
      "Warning 1: Value '434.0' of field geonamesPT.ELEVATION parsed incompletely to integer 434.\n",
      "Warning 1: Value '1137.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1137.\n",
      "Warning 1: Value '168.0' of field geonamesPT.ELEVATION parsed incompletely to integer 168.\n",
      "Warning 1: Value '190.0' of field geonamesPT.ELEVATION parsed incompletely to integer 190.\n",
      "Warning 1: Value '181.0' of field geonamesPT.ELEVATION parsed incompletely to integer 181.\n",
      "Warning 1: Value '571.0' of field geonamesPT.ELEVATION parsed incompletely to integer 571.\n",
      "Warning 1: Value '196.0' of field geonamesPT.ELEVATION parsed incompletely to integer 196.\n",
      "Warning 1: Value '723.0' of field geonamesPT.ELEVATION parsed incompletely to integer 723.\n",
      "Warning 1: Value '845.0' of field geonamesPT.ELEVATION parsed incompletely to integer 845.\n",
      "Warning 1: Value '527.0' of field geonamesPT.ELEVATION parsed incompletely to integer 527.\n",
      "Warning 1: Value '845.0' of field geonamesPT.ELEVATION parsed incompletely to integer 845.\n",
      "Warning 1: Value '328.0' of field geonamesPT.ELEVATION parsed incompletely to integer 328.\n",
      "Warning 1: Value '320.0' of field geonamesPT.ELEVATION parsed incompletely to integer 320.\n",
      "Warning 1: Value '204.0' of field geonamesPT.ELEVATION parsed incompletely to integer 204.\n",
      "Warning 1: Value '281.0' of field geonamesPT.ELEVATION parsed incompletely to integer 281.\n",
      "Warning 1: Value '286.0' of field geonamesPT.ELEVATION parsed incompletely to integer 286.\n",
      "Warning 1: Value '213.0' of field geonamesPT.ELEVATION parsed incompletely to integer 213.\n",
      "Warning 1: Value '255.0' of field geonamesPT.ELEVATION parsed incompletely to integer 255.\n",
      "Warning 1: Value '62.0' of field geonamesPT.ELEVATION parsed incompletely to integer 62.\n",
      "Warning 1: Value '4.0' of field geonamesPT.ELEVATION parsed incompletely to integer 4.\n",
      "Warning 1: Value '695.0' of field geonamesPT.ELEVATION parsed incompletely to integer 695.\n",
      "Warning 1: Value '629.0' of field geonamesPT.ELEVATION parsed incompletely to integer 629.\n",
      "Warning 1: Value '467.0' of field geonamesPT.ELEVATION parsed incompletely to integer 467.\n",
      "Warning 1: Value '275.0' of field geonamesPT.ELEVATION parsed incompletely to integer 275.\n",
      "Warning 1: Value '636.0' of field geonamesPT.ELEVATION parsed incompletely to integer 636.\n",
      "Warning 1: Value '282.0' of field geonamesPT.ELEVATION parsed incompletely to integer 282.\n",
      "Warning 1: Value '541.0' of field geonamesPT.ELEVATION parsed incompletely to integer 541.\n",
      "Warning 1: Value '56.0' of field geonamesPT.ELEVATION parsed incompletely to integer 56.\n",
      "Warning 1: Value '52.0' of field geonamesPT.ELEVATION parsed incompletely to integer 52.\n",
      "Warning 1: Value '56.0' of field geonamesPT.ELEVATION parsed incompletely to integer 56.\n",
      "Warning 1: Value '16.0' of field geonamesPT.ELEVATION parsed incompletely to integer 16.\n",
      "Warning 1: Value '120.0' of field geonamesPT.ELEVATION parsed incompletely to integer 120.\n",
      "Warning 1: Value '120.0' of field geonamesPT.ELEVATION parsed incompletely to integer 120.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning 1: Value '11.0' of field geonamesPT.ELEVATION parsed incompletely to integer 11.\n",
      "Warning 1: Value '7.0' of field geonamesPT.ELEVATION parsed incompletely to integer 7.\n",
      "Warning 1: Value '460.0' of field geonamesPT.ELEVATION parsed incompletely to integer 460.\n",
      "Warning 1: Value '1019.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1019.\n",
      "Warning 1: Value '405.0' of field geonamesPT.ELEVATION parsed incompletely to integer 405.\n",
      "Warning 1: Value '201.0' of field geonamesPT.ELEVATION parsed incompletely to integer 201.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '15.0' of field geonamesPT.ELEVATION parsed incompletely to integer 15.\n",
      "Warning 1: Value '0.0' of field geonamesPT.ELEVATION parsed incompletely to integer 0.\n",
      "Warning 1: Value '81.0' of field geonamesPT.ELEVATION parsed incompletely to integer 81.\n",
      "Warning 1: Value '4.0' of field geonamesPT.ELEVATION parsed incompletely to integer 4.\n",
      "Warning 1: Value '9.0' of field geonamesPT.ELEVATION parsed incompletely to integer 9.\n",
      "Warning 1: Value '1205.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1205.\n",
      "Warning 1: Value '1052.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1052.\n",
      "Warning 1: Value '1076.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1076.\n",
      "Warning 1: Value '1064.0' of field geonamesPT.ELEVATION parsed incompletely to integer 1064.\n",
      "Warning 1: Value '563.0' of field geonamesPT.ELEVATION parsed incompletely to integer 563.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import pandas\n",
    "from osgeo import ogr\n",
    "\n",
    "#Ensure appropriate path\n",
    "cwd = os.getcwd()\n",
    "print(\"current working directory is \", cwd)\n",
    "os.chdir(\"C:\\\\\")\n",
    "cwd = os.getcwd()\n",
    "print(\"current working directory is \", cwd)\n",
    "path = os.path.join('mcsig_git', 'data_load', 'pt')\n",
    "os.chdir(path)\n",
    "print(\"current working directory is \", cwd)\n",
    "\n",
    "#convert txt to csv\n",
    "os.remove(r\"C:\\mcsig_git\\data_load\\pt\\geonamesPT.csv\")\n",
    "read_file = pandas.read_csv(r\"geonamesPT.txt\", sep='\\t')\n",
    "read_file.to_csv(r\"geonamesPT.csv\",header=None,index=None)\n",
    "\n",
    "#Open postgres connection\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "print(\"Connection open\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#!ogrinfo -ro -al geonamesPT.txt -oo X_POSSIBLE_NAMES=field_5 -oo Y_POSSIBLE_NAMES=field_4 -oo KEEP_GEOM_COLUMNS=NO\n",
    "#!ogrinfo geonamesPT.txt\n",
    "#print(\"Checkpoint\")\n",
    "\n",
    "!ogr2ogr -f \"PostgreSQL\" PG:\"host=localhost user=postgres dbname=postgres password=thesis2021\" geonamesPT.csv -oo AUTODETECT_TYPE=YES\n",
    "#-a_srs 'EPSG:4326' #Doublecheck appropriate srs\n",
    "print(\"Successfully loaded geonamesPT\")\n",
    "\n",
    "#Closing the connection\n",
    "conn.close()\n",
    "print(\"Great success!!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5492de73",
   "metadata": {},
   "source": [
    "## Visualize distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb059a87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection open\n",
      "number of coordsGaz: 4449\n",
      "number of placeGaz: 4449\n",
      "GREAT SUCCESS!!!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from osgeo import ogr, osr\n",
    "from shapely import geometry #, wkt\n",
    "import geojson\n",
    "import folium\n",
    "import psycopg2\n",
    "\n",
    "#define variables\n",
    "mapGaz = [] #define an empty list for coordinates of Gazetteer locations\n",
    "\n",
    "#define functions\n",
    "def placeGaz(coords):\n",
    "    for i in coords:\n",
    "        pointGaz = geometry.Point(i[1],i[0])\n",
    "        mapGaz.append(pointGaz)\n",
    "    return mapGaz\n",
    "    \n",
    "\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "print(\"Connection open\")\n",
    "\n",
    "cur.execute(\"SELECT latitude,longitude,name FROM geoname WHERE admin1 = '14' OR admin1 = '19' \") # \n",
    "#cur.execute(\"SELECT latitude,longitude,name FROM geoname\")\n",
    "coordsGaz = cur.fetchall()\n",
    "#print(coordsGaz)\n",
    "print(\"number of coordsGaz: \" + str(len(coordsGaz)))\n",
    "placeGaz(coordsGaz)\n",
    "print(\"number of placeGaz: \" + str(len(mapGaz)))\n",
    "#print(\"mapGaz: \" + str(mapGaz))#remove in production\n",
    "\n",
    "\n",
    "multiGaz = geometry.MultiPoint(mapGaz) #Associate all gazetteer locations into a variable of type multipoint\n",
    "multiJson = geojson.Feature(geometry=multiGaz, properties={})\n",
    "#print(\"multiJson: \" + str(multiJson))#remove in production\n",
    "\n",
    "\n",
    "print(\"GREAT SUCCESS!!!\")\n",
    "\n",
    "#Closing the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a3c04",
   "metadata": {},
   "source": [
    "## Visualize Gazetteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b851a79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.features.GeoJson at 0x27e5d0239a0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapDisp = folium.Map(location=[38.7223,-9.1393], tiles ='Stamen Terrain', zoom_start=8) #define map style\n",
    "folium.GeoJson(multiJson).add_to(mapDisp) #map all gazetteer points\n",
    "#mapDisp #heavy to visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ce76d",
   "metadata": {},
   "source": [
    "## Polygon gazetteer\n",
    "In Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b9dd2e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraneous files removed\n",
      "Beginning freguesias download with wget module\n",
      "100% [########################################################################]           30M / 30M\n",
      "downloaded\n",
      "Freguesias unzipped\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "#tidyup\n",
    "#os.remove(r\"C:\\mcsig_git\\data_load\\concelhos.zip\")\n",
    "#shutil.rmtree(\"C:\\mcsig_git\\data_load\\pt\\concelhos\")\n",
    "#os.mkdir(\"pt\\concelhos\")\n",
    "#os.remove(r\"C:\\mcsig_git\\data_load\\cont-aad-caop2017.zip\")\n",
    "#shutil.rmtree(r\"C:\\mcsig_git\\data_load\\pt\\freguesias\")\n",
    "os.mkdir(r\"pt\\freguesias\")\n",
    "print('extraneous files removed')\n",
    "\n",
    "#download Freguesias\n",
    "print('Beginning freguesias download with wget module')\n",
    "url = 'https://dados.gov.pt/s/resources/freguesias-de-portugal/20181112-195834/cont-aad-caop2017.zip'\n",
    "wget.download(url, 'C:\\mcsig_git\\data_load')\n",
    "print()\n",
    "print(\"downloaded\")\n",
    "with zipfile.ZipFile('C:\\mcsig_git\\data_load\\cont-aad-caop2017.zip', 'r') as zip_ref:\n",
    "                    zip_ref.extractall(r'C:\\mcsig_git\\data_load\\pt\\freguesias')\n",
    "print('Freguesias unzipped')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "632b9def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From UA5 from SAPROG course\n",
      "1\n",
      "3223\n",
      "(-119191.40749999974, 162129.08110000007, -300404.80399999954, 276083.76740000024)\n",
      "<class 'osgeo.osr.SpatialReference'>\n",
      "PROJCS[\"ETRS89 / Portugal TM06\",\n",
      "    GEOGCS[\"ETRS89\",\n",
      "        DATUM[\"European_Terrestrial_Reference_System_1989\",\n",
      "            SPHEROID[\"GRS 1980\",6378137,298.257222101,\n",
      "                AUTHORITY[\"EPSG\",\"7019\"]],\n",
      "            AUTHORITY[\"EPSG\",\"6258\"]],\n",
      "        PRIMEM[\"Greenwich\",0,\n",
      "            AUTHORITY[\"EPSG\",\"8901\"]],\n",
      "        UNIT[\"degree\",0.0174532925199433,\n",
      "            AUTHORITY[\"EPSG\",\"9122\"]],\n",
      "        AUTHORITY[\"EPSG\",\"4258\"]],\n",
      "    PROJECTION[\"Transverse_Mercator\"],\n",
      "    PARAMETER[\"latitude_of_origin\",39.6682583333333],\n",
      "    PARAMETER[\"central_meridian\",-8.13310833333333],\n",
      "    PARAMETER[\"scale_factor\",1],\n",
      "    PARAMETER[\"false_easting\",0],\n",
      "    PARAMETER[\"false_northing\",0],\n",
      "    UNIT[\"metre\",1,\n",
      "        AUTHORITY[\"EPSG\",\"9001\"]],\n",
      "    AXIS[\"Easting\",EAST],\n",
      "    AXIS[\"Northing\",NORTH],\n",
      "    AUTHORITY[\"EPSG\",\"3763\"]]\n",
      "ETRS89\n",
      "!! LAYER DEFINITIONS !!\n",
      "Dicofre - String\n",
      "Freguesia - String\n",
      "Concelho - String\n",
      "Distrito - String\n",
      "TAA - String\n",
      "AREA_EA_Ha - Real\n",
      "AREA_T_Ha - Real\n",
      "Des_Simpli - String\n",
      "Great success!\n"
     ]
    }
   ],
   "source": [
    "##https://pcjericks.github.io/py-gdalogr-cookbook/vector_layers.html\n",
    "#https://www.gispo.fi/en/open-software/importing-spatial-data-to-postgis/\n",
    "#https://postgis.net/docs/using_postgis_dbmanagement.html#loading_geometry_data\n",
    "\n",
    "print(\"From UA5 from SAPROG course\")\n",
    "import psycopg2\n",
    "import os\n",
    "from osgeo import ogr\n",
    "path = os.path.join('pt', 'freguesias')\n",
    "os.chdir(path) #only use when first directing\n",
    "\n",
    "shp = ogr.Open('Cont_AAD_CAOP2017.shp')\n",
    "print(shp.GetLayerCount())\n",
    "layer = shp.GetLayer(0)\n",
    "print (layer.GetFeatureCount())\n",
    "print (layer.GetExtent())\n",
    "\n",
    "srs = layer.GetSpatialRef()\n",
    "print (type(srs))\n",
    "print(srs.ExportToPrettyWkt())\n",
    "print(srs.GetAttrValue('GEOGCS'))\n",
    "\n",
    "print(\"!! LAYER DEFINITIONS !!\")\n",
    "layerDef = layer.GetLayerDefn()\n",
    "\n",
    "for i in range(layerDef.GetFieldCount()):\n",
    "    fieldDef = layerDef.GetFieldDefn(i)\n",
    "    print (fieldDef.GetName(), '-', fieldDef.GetTypeName())\n",
    "    \n",
    "print(\"Great success!\")\n",
    "shp.Destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fff35c4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shp2pgsql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c71a68c73bed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#https://notebook.community/OSGeo-live/CesiumWidget/GSOC/notebooks/Access%20to%20Geospatial%20data/GDAL-OGR%20Quickstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mshp2pgsql\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#os.environ['PROJ_LIB'] = 'C:\\\\gdalwin64-3.3.0\\\\bin\\\\proj7\\\\share'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shp2pgsql'"
     ]
    }
   ],
   "source": [
    "#https://notebook.community/OSGeo-live/CesiumWidget/GSOC/notebooks/Access%20to%20Geospatial%20data/GDAL-OGR%20Quickstart\n",
    "import psycopg2\n",
    "import shp2pgsql\n",
    "import os\n",
    "#os.environ['PROJ_LIB'] = 'C:\\\\gdalwin64-3.3.0\\\\bin\\\\proj7\\\\share'\n",
    "#os.environ['GDAL_DATA'] = 'C:\\\\gdalwin64-3.3.0\\\\bin\\\\gdal-data'\n",
    "#import gdal\n",
    "from osgeo import ogr\n",
    "\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "print(\"Connection open\")\n",
    "\n",
    "#Drop table if already exists\n",
    "#manually dropping\n",
    "cur.execute(\"DROP TABLE IF EXISTS cont_aad_caop2017 CASCADE\")\n",
    "print (\"cont_aad_caop2017 dropped\")\n",
    "\n",
    "\n",
    "path = os.path.join('pt', 'freguesias')\n",
    "os.chdir(path) #only use when first directing\n",
    "\n",
    "!ogrinfo Cont_AAD_CAOP2017.shp\n",
    "print(\"Checkpoint\")\n",
    "\n",
    "#Failing here:\n",
    "#!ogr2ogr -progress -overwrite -f \"PostgreSQL\" PG:\"host=localhost user=postgres dbname=postgres password=thesis2021\" Cont_AAD_CAOP2017.shp -nlt POLYGON\n",
    "#!ogr2ogr -progress -overwrite -f \"PostgreSQL\" PG:\"host=localhost user=postgres dbname=postgres password=thesis2021\" Cont_AAD_CAOP2017.shp -nln public.freguesias_shp lco GEOMETRY_NAME=geom -nlt POLYGON\n",
    "!shp2pgsql -s 4326 Cont_AAD_CAOP2017 public.freguesias_shp #https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781784391645/1/ch01lvl1sec2/importing-shape-files-using-shp2pgsql\n",
    "print(\"Successfully loaded shp\")\n",
    "\n",
    "#Closing the connection\n",
    "conn.close()\n",
    "\n",
    "#What to do about this?:\n",
    "#ERROR 1: PROJ: proj_identify: C:\\Program Files\\PostgreSQL\\13\\share\\contrib\\postgis-3.1\\proj\\proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "acee8cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection open\n",
      "1\n",
      "# preloaded freguesias: 3223\n",
      "(-119191.40749999974, 162129.08110000007, -300404.80399999954, 276083.76740000024)\n",
      "Number of loaded freguesias: 3223\n",
      "Great success!!!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "#os.environ['PROJ_LIB'] = 'C:\\\\gdalwin64-3.3.0\\\\bin\\\\proj7\\\\share'\n",
    "#os.environ['GDAL_DATA'] = 'C:\\\\gdalwin64-3.3.0\\\\bin\\\\gdal-data'\n",
    "#import gdal\n",
    "#from osgeo import ogr\n",
    "\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "print(\"Connection open\")\n",
    "\n",
    "shp = ogr.Open('Cont_AAD_CAOP2017.shp')\n",
    "print(shp.GetLayerCount())\n",
    "layer = shp.GetLayer(0)\n",
    "print (\"# preloaded freguesias: \" + str(layer.GetFeatureCount()))\n",
    "print (layer.GetExtent())\n",
    "shp.Destroy()\n",
    "\n",
    "cur.execute(\"SELECT COUNT(ogc_fid) FROM cont_aad_caop2017\")\n",
    "#numFreg = cur.fetchall()\n",
    "numFreg = int(cur.fetchone()[0])\n",
    "print(\"Number of loaded freguesias: \" + str(numFreg))\n",
    "print(\"Great success!!!\")\n",
    "\n",
    "\n",
    "#Closing the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9642366",
   "metadata": {},
   "source": [
    "Neither polygons nor points are loading as spatial data in postgres (QGIS doesn't recognize as spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05b60ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection open\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A LinearRing must have at least 3 coordinate tuples",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\mcsig_git\\env\\lib\\site-packages\\shapely\\speedups\\_speedups.pyx\u001b[0m in \u001b[0;36mshapely.speedups._speedups.geos_linearring_from_py\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute '__array_interface__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-5a9d4036f1db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#polygon = wkb.load(firstPoly)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#polygon.wkb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmapPoly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPolygon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirstPoly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\mcsig_git\\env\\lib\\site-packages\\shapely\\geometry\\polygon.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, shell, holes)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshell\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeos_polygon_from_py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mholes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_geom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\mcsig_git\\env\\lib\\site-packages\\shapely\\geometry\\polygon.py\u001b[0m in \u001b[0;36mgeos_polygon_from_py\u001b[1;34m(shell, holes)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshell\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeos_linearring_from_py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\mcsig_git\\env\\lib\\site-packages\\shapely\\speedups\\_speedups.pyx\u001b[0m in \u001b[0;36mshapely.speedups._speedups.geos_linearring_from_py\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: A LinearRing must have at least 3 coordinate tuples"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "from osgeo import ogr\n",
    "from shapely import geometry, wkb\n",
    "\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=thesis2021\")\n",
    "cur = conn.cursor()\n",
    "print(\"Connection open\")\n",
    "\n",
    "cur.execute(\"SELECT wkb_geometry FROM cont_aad_caop2017\")\n",
    "firstPoly = cur.fetchone()\n",
    "#polygon = wkb.load(firstPoly)\n",
    "#polygon.wkb\n",
    "mapPoly = geometry.Polygon(firstPoly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ded01d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argon2-cffi==20.1.0\n",
      "async-generator==1.10\n",
      "attrs==21.2.0\n",
      "backcall==0.2.0\n",
      "bleach==3.3.0\n",
      "branca==0.4.2\n",
      "certifi==2021.5.30\n",
      "cffi==1.14.5\n",
      "chardet==4.0.0\n",
      "click==8.0.1\n",
      "colorama==0.4.4\n",
      "decorator==5.0.9\n",
      "defusedxml==0.7.1\n",
      "entrypoints==0.3\n",
      "Flask==2.0.1\n",
      "folium==0.12.1\n",
      "GDAL @ file:///C:/Users/calli/Downloads/GDAL-3.3.0-cp39-cp39-win_amd64.whl\n",
      "geojson==2.5.0\n",
      "hurry.filesize==0.9\n",
      "idna==2.10\n",
      "ipykernel==5.5.5\n",
      "ipython==7.24.1\n",
      "ipython-genutils==0.2.0\n",
      "itsdangerous==2.0.1\n",
      "jedi==0.18.0\n",
      "Jinja2==3.0.1\n",
      "jsonschema==3.2.0\n",
      "jupyter-client==6.1.12\n",
      "jupyter-core==4.7.1\n",
      "jupyterlab-pygments==0.1.2\n",
      "MarkupSafe==2.0.1\n",
      "matplotlib-inline==0.1.2\n",
      "mistune==0.8.4\n",
      "mod-wsgi==4.8.0\n",
      "nbclient==0.5.3\n",
      "nbconvert==6.0.7\n",
      "nbformat==5.1.3\n",
      "nest-asyncio==1.5.1\n",
      "notebook==6.4.0\n",
      "numpy==1.20.3\n",
      "packaging==20.9\n",
      "pandocfilters==1.4.3\n",
      "parso==0.8.2\n",
      "pickleshare==0.7.5\n",
      "prometheus-client==0.11.0\n",
      "prompt-toolkit==3.0.18\n",
      "psycopg2==2.8.6\n",
      "pycparser==2.20\n",
      "Pygments==2.9.0\n",
      "pyparsing==2.4.7\n",
      "pyrsistent==0.17.3\n",
      "python-dateutil==2.8.1\n",
      "python3-wget==0.0.2b1\n",
      "pywin32==301\n",
      "pywinpty==1.1.1\n",
      "pyzmq==22.1.0\n",
      "requests==2.25.1\n",
      "Send2Trash==1.5.0\n",
      "Shapely==1.7.1\n",
      "six==1.16.0\n",
      "terminado==0.10.0\n",
      "testpath==0.5.0\n",
      "tornado==6.1\n",
      "traitlets==5.0.5\n",
      "urllib3==1.26.5\n",
      "wcwidth==0.2.5\n",
      "webencodings==0.5.1\n",
      "Werkzeug==2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf540047",
   "metadata": {},
   "source": [
    "## Match Spatial\n",
    "in dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b5942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68450950",
   "metadata": {},
   "source": [
    "## Next:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa6b9aa",
   "metadata": {},
   "source": [
    "1. Integrate with GIT - DONE\n",
    "2. Finish adding the full data model - DONE\n",
    "3. Dimension the data to the model - DONE\n",
    "4. Load GeoNames to model - DONE\n",
    "4. Create Lisbon focused gazetteer - DONE\n",
    "4. Associate spatial \n",
    "5. Retreive data in JSON via web service\n",
    "6. Begin front end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e783a79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
